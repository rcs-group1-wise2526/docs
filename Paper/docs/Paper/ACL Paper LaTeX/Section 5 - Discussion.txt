\section{Discussion}

Our experiments expose some very important realities concerning the abilities of LLMs to participate in testing for psychometric constructs as simulacra for human populations. Our first conclusion to be drawn concerning model outputs is the primacy of model choice/family origin over prompted language or, at least insofar as the constructs of the BFI-2 are concerned, which domain was analyzed. Put simply, the primary indicator of end model behavior, whether results would be psychometrically consistent, both through the new and traditional method pipelines, was the model being tested. This is not to say that the latter attributes bore no effect on the outcomes we observed, however. Language choice did appear to present an effect on model outcomes in a variety of situations. For example, in the assessment of model alignment across languages, the pairings that appeared to be most aligned for each model seemed to be between the languages most closely associated with the model’s training origin and those least associated. For instance, as a model of French origin, Mistral showed the most alignment between English and Chinese. In the opposite case, DeepSeek, a model of Chinese origin shows the most divergence between English and Chinese. We speculate whether these could be indicators that in cases where languages are less represented in a model’s training data, its psychometric profile more closely aligns with that of the model’s primary linguistic training base. While this effect appears to be relatively small, we highlight it as an interesting potential observation for further investigation.

Our secondary key conclusion is simply a reflection of the great many issues we experienced over the course of our experiments with model invariance. Between both our MTDT method and traditional method testing, the majority of our results exhibited the invariance problem to some degree or another, a fact that we postulate may be a shortcoming of LLM simulation of psychometric constructs more generally. While some models such as the Mistral family (Mistral Small 3.2 in traditional testing and Ministral 8B and 14B in MTDT method testing) generally showed themselves to provide more consistently psychometrically robust output data, the sheer prevalence of the problem across so many other models and under different methods demands us to urge a great deal of caution when attempting to simulate human psychometric constructs through LLM testing.